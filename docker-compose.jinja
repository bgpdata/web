version: '3'
####
# BGPDATA - BGP Data Collection and Analytics Service
# 
# This software is part of the BGPDATA project, which is designed to collect, process, and analyze BGP data from various sources.
# It helps researchers and network operators get insights into their network by providing a scalable and reliable way to analyze and inspect historical and live BGP data from Route Collectors around the world.
# 
# Author: Robin Röper
# 
# © 2024 BGPDATA. All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions, and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions, and the following disclaimer in the documentation and/or other materials provided with the distribution.
# 3. Neither the name of BGPDATA nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#####
services:
    ####
    # Core Application Services
    #
    # The following services form the core of the application, providing essential
    # meta databases, near-realtime aggregation infrastructure and web applications.
    #
    # The 'core-db' service manages the PostgreSQL database, utilizing TimescaleDB for
    # efficient handling of time-series data.
    #
    # The 'core-web' service is the main application server, built with Flask
    # and served using Gunicorn with Uvicorn workers for asynchronous processing.
    #
    # The 'core-collector-*' service connects to a Kafka stream, processes BGP messages,
    # and forwards them to the OpenBMP collector.
    ####
    core-db:
        image: timescale/timescaledb:latest-pg13
        restart: unless-stopped
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U bgpdata -d default"]
            interval: 30s
            timeout: 10s
            retries: 5
        environment:
            POSTGRES_DB: default
            POSTGRES_USER: bgpdata
            POSTGRES_PASSWORD: bgpdata
        ports:
            - "5432:5432"
        volumes:
            - core_postgres_data:/var/lib/postgresql/data

    core-web:
        {%- if production %}
        image: bgpdata/bgpdata:{{ version | default('latest') }}
        {%- else %}
        build: .
        {%- endif %}
        restart: unless-stopped
        deploy:
            labels:
                - "traefik.enable=true"
                - "traefik.http.routers.bgpdata.rule=Host(`bgp-data.net`)"
                - "traefik.http.routers.bgpdata.entrypoints=websecure"
                - "traefik.http.routers.bgpdata.tls.certresolver=bgpdata"
                - "traefik.http.services.bgpdata.loadbalancer.server.port=8080"
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        environment:
            POSTGRESQL_HOST: "core-db"
            POSTGRESQL_PORT: 5432
            POSTGRESQL_DB: "default"
            POSTGRESQL_USER: "bgpdata"
            POSTGRESQL_PASSWORD: "bgpdata"
            POSTMARK_API_KEY: /run/secrets/postmark_api_key
            SECRET_KEY: /run/secrets/flask_secret_key
        depends_on:
            core-db:
                condition: service_healthy
        working_dir: /app
        volumes:
            {%- if not production %}
            - .:/app
            {%- endif %}
        entrypoint: >
            /bin/sh -c "python manage.py migrate && python manage.py run --host 0.0.0.0"

    core-traefik:
        image: traefik:v2.4
        ports:
            - "80:80"
            - "443:443"
        deploy:
            placement:
                constraints:
                - node.role == manager
        command:
            - "--entrypoints.web.address=:80"
            - "--entrypoints.websecure.address=:443"
            - "--providers.docker.swarmMode=true"
            - "--providers.docker.exposedbydefault=false"
            - "--certificatesresolvers.bgpdata.acme.httpchallenge.entrypoint=web"
            - "--certificatesresolvers.bgpdata.acme.email=hostmaster@bgp-data.net"
            - "--certificatesresolvers.bgpdata.acme.storage=/acme.json"
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock:ro
            - core_traefik_data:/acme.json

    {%- for host in ris %}
    core-collector-{{ host | replace(".", "-") }}:
        {%- if production %}
        image: bgpdata/bgpdata:{{ version | default('latest') }}
        {%- else %}
        build: .
        {%- endif %}
        restart: unless-stopped
        stop_signal: SIGTERM                    # Wind down collector safely before stopping
        stop_grace_period: 20s                  # Wait for 20 seconds before forcefully stopping
        environment:
            POSTGRESQL_HOST: core-db
            POSTGRESQL_PORT: 5432
            POSTGRESQL_DB: default
            POSTGRESQL_USER: bgpdata
            POSTGRESQL_PASSWORD: bgpdata
            COLLECTOR_HOST: {{ host }}
            COLLECTOR_KAFKA_CONNECT: stream.ris-kafka.com:9092
            COLLECTOR_OPENBMP_CONNECT: openbmp-collector-{{ host | replace(".", "-") }}:5000
        depends_on:
            core-db:
                condition: service_healthy
            openbmp-collector:
                condition: service_healthy
        working_dir: /app
        volumes:
            {%- if not production %}
            - .:/app
            {%- endif %}
            - core_{{ host | replace(".", "_") | replace("-", "_") }}_data:/var/lib/rocksdb
        entrypoint: >
            python manage.py collector
    {% endfor %}

    {%- for host in routeviews %}
    core-collector-{{ host | replace(".", "-") }}:
        {%- if production %}
        image: bgpdata/bgpdata:{{ version | default('latest') }}
        {%- else %}
        build: .
        {%- endif %}
        restart: unless-stopped
        stop_signal: SIGTERM                    # Wind down collector safely before stopping
        stop_grace_period: 20s                  # Wait for 20 seconds before forcefully stopping
        environment:
            POSTGRESQL_HOST: core-db
            POSTGRESQL_PORT: 5432
            POSTGRESQL_DB: default
            POSTGRESQL_USER: bgpdata
            POSTGRESQL_PASSWORD: bgpdata
            COLLECTOR_HOST: {{ host }}
            COLLECTOR_KAFKA_CONNECT: stream.routeviews.org:9092
            COLLECTOR_OPENBMP_CONNECT: openbmp-collector-{{ host | replace(".", "-") }}:5000
        depends_on:
            core-db:
                condition: service_healthy
            openbmp-collector:
                condition: service_healthy
        working_dir: /app
        volumes:
            {%- if not production %}
            - .:/app
            {%- endif %}
            - core_{{ host | replace(".", "_") | replace("-", "_") }}_data:/var/lib/rocksdb
        entrypoint: >
            python manage.py collector
    {% endfor %}

    ###
    # OpenBMP (Open Border Gateway Protocol Monitoring Protocol) services
    #
    # These services are responsible for collecting, storing, and analyzing BGP data.
    # They consume BGP messages from a Kafka stream, process them, and store the results
    # in a PostgreSQL database. The data is then used to provide insights into the global
    # routing table, including route visibility, prefix reachability, and AS path analysis.
    #
    # The 'openbmp-db' service manages the PostgreSQL database where the processed BGP
    # data is stored. It ensures data integrity, handles database migrations, and provides
    # a reliable storage backend for the OpenBMP application.
    #
    # The 'openbmp-whois' service provides a whois service for the BGP data. It allows users
    # to query the database for whois information about BGP peers.
    #
    # The 'openbmp-zookeeper' service manages the Zookeeper cluster, providing a centralized
    # coordination service for the Kafka cluster. It ensures that the Kafka brokers are
    # properly configured and synchronized, maintaining a consistent state across the cluster.
    #
    # The 'openbmp-kafka' service connects to the Kafka stream, consumes BGP messages,
    # and processes them in real-time. It ensures that the data is correctly formatted
    # and ready for storage in the PostgreSQL database.
    #
    # The 'openbmp-app' service provides a web interface and API for accessing the stored
    # BGP data. It allows users to query the database, visualize BGP data, and generate
    # reports on routing behavior and anomalies.
    #
    # The 'openbmp-collector-*' service ingests BMP messages from the 'core-collector-*' service.
    # Which is collecting from various other collectors and RIB dumps.
    #
    # The 'openbmp-grafana' service provides a Grafana dashboard for visualizing the data
    # collected and processed by the application, offering insights and monitoring capabilities.
    ###
    openbmp-db:
        image: openbmp/postgres:2.2.1
        platform: linux/amd64
        restart: unless-stopped
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U openbmp"]
            interval: 30s
            timeout: 10s
            retries: 5
        privileged: true
        shm_size: 1536m
        ports:
            - "5433:5432"
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        volumes:
            - obmp_postgres_data:/var/lib/postgresql/data
            - obmp_timescale_data:/var/lib/postgresql/ts
        command: >
            -c max_wal_size=10GB
        environment:
            POSTGRES_PASSWORD: openbmp
            POSTGRES_USER: openbmp
            POSTGRES_DB: openbmp
        
    openbmp-app:
        image: openbmp/psql-app:2.2.2
        platform: linux/amd64
        restart: unless-stopped
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        depends_on:
            openbmp-db:
                condition: service_healthy
            openbmp-kafka:
                condition: service_healthy
        volumes:
            - obmp_config_data:/config
        environment:
            MEM: 3                                           # Set memory to at least 2GB but ideally 4GB
            KAFKA_FQDN: openbmp-kafka:29092
            RPKI_URL: https://rpki.cloudflare.com/rpki.json  # define the URL to retrieve json endoed RPKI data
            RPKI_PASS: None
            RPKI_USER: None
            ENABLE_RPKI: 1                                   # 1 enables, 0 disables RPKI sync
            ENABLE_IRR: 1                                    # 1 enables, 0 disables IRR sync
            ENABLE_DBIP: 1                                   # 1 enables, 0 disables DBIP import
            POSTGRES_REPORT_WINDOW: '8 minute'               # default POSTGRESS window to select when building
                                                             #   summary tables. For deployments that absorb large
                                                             #   bursts increase the value, ex 60 minute
            POSTGRES_PASSWORD: openbmp
            POSTGRES_USER: openbmp
            POSTGRES_DB: openbmp
            POSTGRES_HOST: openbmp-db
            POSTGRES_PORT: 5432
            POSTGRES_DROP_peer_event_log: '1 month'
            POSTGRES_DROP_stat_reports: '1 day'
            POSTGRES_DROP_ip_rib_log: '1 day'
            POSTGRES_DROP_alerts: '1 day'
            POSTGRES_DROP_ls_nodes_log: '2 days'
            POSTGRES_DROP_ls_links_log: '2 days'
            POSTGRES_DROP_ls_prefixes_log: '2 days'
            POSTGRES_DROP_stats_chg_byprefix: '1 day'
            POSTGRES_DROP_stats_chg_byasn: '1 day'
            POSTGRES_DROP_stats_chg_bypeer: '1 day'
            POSTGRES_DROP_stats_ip_origins: '1 day'
            POSTGRES_DROP_stats_peer_rib: '1 day'
            POSTGRES_DROP_stats_peer_update_counts: '1 day'

    {%- for host in ris + routeviews %}
    openbmp-collector-{{ host | replace(".", "-") }}:
        platform: linux/amd64
        restart: unless-stopped
        healthcheck:
            test: ["CMD-SHELL", "cat", "< /dev/null >", "/dev/tcp/localhost/5000"]
            interval: 30s
            timeout: 10s
            retries: 3
        image: openbmp/collector:2.2.3
        depends_on:
            openbmp-db:
                condition: service_healthy
            openbmp-kafka:
                condition: service_healthy
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        volumes:
            - obmp_config_data:/config
        environment:
            KAFKA_FQDN: openbmp-kafka:29092
    {% endfor %}

    openbmp-whois:
        image: openbmp/whois:2.2.0
        platform: linux/amd64
        restart: unless-stopped
        healthcheck:
            test: ["CMD-SHELL", "cat", "< /dev/null >", "/dev/tcp/localhost/43"]
            interval: 30s
            timeout: 10s
            retries: 3
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        volumes:
            - obmp_config_data:/config
        depends_on:
            openbmp-db:
                condition: service_healthy
        ports:
            - "4300:43"
        environment:
            POSTGRES_PASSWORD: openbmp
            POSTGRES_USER: openbmp
            POSTGRES_DB: openbmp
            POSTGRES_HOST: openbmp-db
            POSTGRES_PORT: 5433

    openbmp-zookeeper:
        image: confluentinc/cp-zookeeper:7.7.1
        restart: unless-stopped
        healthcheck:
            test: ["CMD-SHELL", "nc -z localhost 2181 || exit -1"]
            interval: 30s
            timeout: 10s
            retries: 5
        volumes:
            - obmp_zookeeper_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    openbmp-kafka:
        image: confluentinc/cp-kafka:7.7.1
        restart: unless-stopped
        healthcheck:
            test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "openbmp-kafka:29092"]
            interval: 30s
            timeout: 60s # Command may take some time.
            retries: 10
        depends_on:
            openbmp-zookeeper:
                condition: service_healthy
        # Change the mount point to where you want to store Kafka data.
        #   Normally 80GB or more
        volumes:
            - obmp_kafka_data:/var/lib/kafka/data
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: openbmp-zookeeper:2181
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092
            # Change/add listeners based on your FQDN that the host and other containers can access.  You can use
            #    an IP address as well. By default, only within the compose/containers can Kafka be accesssed
            #    using port 29092. Outside access can be enabled, but you should use an FQDN listener.
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://openbmp-kafka:29092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_NUM_PARTITIONS: 8
            KAFKA_LOG_RETENTION_MINUTES: 90
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2

    openbmp-grafana:
        image: grafana/grafana:9.1.7
        restart: unless-stopped
        healthcheck:
            test: ["CMD", "wget", "--spider", "http://localhost:3000"]
            interval: 30s
            timeout: 10s
            retries: 3
        user: root
        ports:
            - "3000:3000"
        volumes:
            {%- if not production %}
            - ./grafana:/var/lib/grafana
            - ./grafana/provisioning/:/etc/grafana/provisioning/
            {%- endif %}
        environment:
            GF_SECURITY_ADMIN_PASSWORD: openbmp
            GF_AUTH_ANONYMOUS_ENABLED: true
            GF_USERS_HOME_PAGE: d/obmp-home/obmp-home
            GF_INSTALL_PLUGINS: agenty-flowcharting-panel,grafana-piechart-panel,grafana-worldmap-panel,grafana-simple-json-datasource,vonage-status-panel

# Define volumes
volumes:
    {%- for host in ris + routeviews %}
    core_{{ host | replace(".", "_") | replace("-", "_") }}_data:
    {%- endfor %}
    core_traefik_data:
    core_postgres_data:
    obmp_config_data:
    obmp_postgres_data:
    obmp_timescale_data:
    obmp_zookeeper_data:
    obmp_kafka_data: