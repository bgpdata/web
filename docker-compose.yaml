services:
    ####
    # Core Application Services
    #
    # The following services form the core of the application, providing essential
    # meta databases, near-realtime aggregation infrastructure and web applications.
    #
    # The 'core-db' service manages the PostgreSQL database, utilizing TimescaleDB for
    # efficient handling of time-series data.
    #
    # The 'core-web' service is the main application server, built with Flask
    # and served using Gunicorn with Uvicorn workers for asynchronous processing.
    #
    # The 'core-collector' service connects to RIPE NCC's Kafka stream, processes BGP messages,
    # and stores them in the PostgreSQL database.
    #
    # The 'core-aggregator' service periodically analyzes the collected data to identify
    # and categorize RIS peers, storing this information in Redis for quick access.
    #
    # The 'core-grafana' service provides a Grafana dashboard for visualizing the data
    # collected and processed by the application, offering insights and monitoring capabilities.
    ####
    core-db:
        image: timescale/timescaledb:latest-pg13
        container_name: core-db
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U core"]
            interval: 30s
            timeout: 10s
            retries: 5
        environment:
            POSTGRES_USER: core
            POSTGRES_PASSWORD: core
            POSTGRES_DB: default
        ports:
            - "5432:5432"
        volumes:
            - core_pg_data:/var/lib/postgresql/data

    core-web:
        build: .
        container_name: core-web
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        environment:
            - POSTGRESQL_DATABASE=postgresql+asyncpg://core:core@core-db:5432/default
            - POSTMARK_API_KEY=your-postmark-api-key
            - SECRET_KEY=your-flask-secret-key
            - ENVIRONMENT=development
        ports:
            - "8080:8080"
        depends_on:
            core-db:
                condition: service_healthy
        working_dir: /app
        volumes:
            - .:/app
        entrypoint: >
            /bin/sh -c "alembic upgrade head && gunicorn --bind 0.0.0.0:8080 --workers 4 --worker-class uvicorn.workers.UvicornWorker --reload --log-level info --access-logfile - --error-logfile - 'app:asgi_app'"

    core-collector:
        build: .
        container_name: core-collector
        environment:
            - POSTGRESQL_DATABASE=postgresql+asyncpg://core:core@core-db:5432/default
            - SASL_KAFKA_USERNAME=public
            - SASL_KAFKA_PASSWORD=public
        depends_on:
            openbmp-kafka:
                condition: service_healthy
        working_dir: /app
        volumes:
            - .:/app
        entrypoint: >
            python services/collector.py

    #core-aggregator:
    #    build: .
    #    container_name: core-ris-peers
    #    environment:
    #        - POSTGRESQL_DATABASE=postgresql+asyncpg://core:core@core-db:5432/default
    #        - REDIS_DATABASE=redis://redis:6379
    #    depends_on:
    #        core-db:
    #            condition: service_healthy
    #    working_dir: /app
    #    volumes:
    #        - .:/app
    #    entrypoint: >
    #        python services/ris_peers.py

    core-grafana:
        container_name: core-grafana
        image: grafana/grafana:9.1.7
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:3000"]
            interval: 30s
            timeout: 10s
            retries: 3
        ports:
            - "3000:3000"
        volumes:
            - ./grafana:/var/lib/grafana
            - ./grafana:/etc/grafana/provisioning/
        environment:
            - GF_SECURITY_ADMIN_PASSWORD=openbmp
            - GF_AUTH_ANONYMOUS_ENABLED=true
            - GF_USERS_HOME_PAGE=d/obmp-home/obmp-home
            - GF_INSTALL_PLUGINS=agenty-flowcharting-panel,grafana-piechart-panel,grafana-worldmap-panel,grafana-simple-json-datasource,vonage-status-panel

    ###
    # OpenBMP (Open Border Gateway Protocol Monitoring Protocol) services
    #
    # These services are responsible for collecting, storing, and analyzing BGP data.
    # They consume BGP messages from a Kafka stream, process them, and store the results
    # in a PostgreSQL database. The data is then used to provide insights into the global
    # routing table, including route visibility, prefix reachability, and AS path analysis.
    #
    # The 'openbmp-db' service manages the PostgreSQL database where the processed BGP
    # data is stored. It ensures data integrity, handles database migrations, and provides
    # a reliable storage backend for the OpenBMP application.
    #
    # The 'openbmp-whois' service provides a whois service for the BGP data. It allows users
    # to query the database for whois information about BGP peers.
    #
    # The 'openbmp-zookeeper' service manages the Zookeeper cluster, providing a centralized
    # coordination service for the Kafka cluster. It ensures that the Kafka brokers are
    # properly configured and synchronized, maintaining a consistent state across the cluster.
    #
    # The 'openbmp-kafka' service connects to the Kafka stream, consumes BGP messages,
    # and processes them in real-time. It ensures that the data is correctly formatted
    # and ready for storage in the PostgreSQL database.
    #
    # The 'openbmp-app' service provides a web interface and API for accessing the stored
    # BGP data. It allows users to query the database, visualize BGP data, and generate
    # reports on routing behavior and anomalies.
    ###
    openbmp-db:
        container_name: openbmp-db
        image: openbmp/postgres:2.2.1
        platform: linux/amd64
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U openbmp"]
            interval: 30s
            timeout: 10s
            retries: 5
        privileged: true
        shm_size: 1536m
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        volumes:
            - obmp_pg_data:/var/lib/postgresql/data
            - obmp_ts_data:/var/lib/postgresql/ts
        command: >
            -c max_wal_size=10GB
        environment:
            - POSTGRES_PASSWORD=openbmp
            - POSTGRES_USER=openbmp
            - POSTGRES_DB=openbmp
        
    openbmp-app:
        container_name: openbmp-app
        image: openbmp/psql-app:2.2.2
        platform: linux/amd64
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:9005"]
            interval: 30s
            timeout: 10s
            retries: 3
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        depends_on:
            openbmp-db:
                condition: service_healthy
            openbmp-kafka:
                condition: service_healthy
        ports:
            - "9005:9005"
        volumes:
            - obmp_ap_data:/config
        environment:
            - MEM=3                                           # Set memory to at least 2GB but ideally 4GB
            - KAFKA_FQDN=openbmp-kafka:29092
            - RPKI_URL=https://rpki.cloudflare.com/rpki.json  # define the URL to retrieve json endoed RPKI data
            - RPKI_PASS=None
            - RPKI_USER=None
            - ENABLE_RPKI=1                                   # 1 enables, 0 disables RPKI sync
            - ENABLE_IRR=1                                    # 1 enables, 0 disables IRR sync
            - ENABLE_DBIP=1                                   # 1 enables, 0 disables DBIP import
            - POSTGRES_REPORT_WINDOW='8 minute'               # default POSTGRESS window to select when building
                                                              #   summary tables. For deployments that absorb large
                                                              #   bursts increase the value, ex 60 minute
            - POSTGRES_PASSWORD=openbmp
            - POSTGRES_USER=openbmp
            - POSTGRES_DB=openbmp
            - POSTGRES_HOST=openbmp-db
            - POSTGRES_PORT=5432
            - POSTGRES_DROP_peer_event_log='1 year'
            - POSTGRES_DROP_stat_reports='4 weeks'
            - POSTGRES_DROP_ip_rib_log='4 weeks'
            - POSTGRES_DROP_alerts='4 weeks'
            - POSTGRES_DROP_ls_nodes_log='4 months'
            - POSTGRES_DROP_ls_links_log='4 months'
            - POSTGRES_DROP_ls_prefixes_log='4 months'
            - POSTGRES_DROP_stats_chg_byprefix='4 weeks'
            - POSTGRES_DROP_stats_chg_byasn='4 weeks'
            - POSTGRES_DROP_stats_chg_bypeer='4 weeks'
            - POSTGRES_DROP_stats_ip_origins='4 weeks'
            - POSTGRES_DROP_stats_peer_rib='4 weeks'
            - POSTGRES_DROP_stats_peer_update_counts='4 weeks'

    openbmp-whois:
        container_name: openbmp-whois
        image: openbmp/whois:2.2.0
        platform: linux/amd64
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:43"]
            interval: 30s
            timeout: 10s
            retries: 3
        sysctls:
            - net.ipv4.tcp_keepalive_intvl=30
            - net.ipv4.tcp_keepalive_probes=5
            - net.ipv4.tcp_keepalive_time=180
        depends_on:
            openbmp-db:
                condition: service_healthy
        ports:
            - "4300:43"
        environment:
            - POSTGRES_PASSWORD=openbmp
            - POSTGRES_USER=openbmp
            - POSTGRES_DB=openbmp
            - POSTGRES_HOST=openbmp-db
            - POSTGRES_PORT=5433

    openbmp-zookeeper:
        container_name: openbmp-zookeeper
        image: confluentinc/cp-zookeeper:7.1.1
        platform: linux/amd64
        volumes:
            - obmp_zk_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    openbmp-kafka:
        container_name: openbmp-kafka
        image: confluentinc/cp-kafka:7.1.1
        platform: linux/amd64
        healthcheck:
            test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "openbmp-kafka:29092"]
            interval: 30s
            timeout: 10s
            retries: 5
        # Change the mount point to where you want to store Kafka data.
        #   Normally 80GB or more
        volumes:
            - obmp_kf_data:/var/lib/kafka/data
        ports:
            - "9092:9092"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: openbmp-zookeeper:2181
            # Change/add listeners based on your FQDN that the host and other containers can access.  You can use
            #    an IP address as well. By default, only within the compose/containers can Kafka be accesssed
            #    using port 29092. Outside access can be enabled, but you should use an FQDN listener.
            #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://<FQDN>:9092
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://openbmp-kafka:29092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_NUM_PARTITIONS: 8
            KAFKA_LOG_RETENTION_MINUTES: 90
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2


# Define volumes
volumes:
    core_pg_data:
    obmp_pg_data:
    obmp_ts_data:
    obmp_zk_data:
    obmp_kf_data:
    obmp_ap_data: